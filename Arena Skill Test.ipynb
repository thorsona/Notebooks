{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## INSTRUCTIONS ##\n",
    "\n",
    "use_dir = 'C:/Users/Anna/Documents/Github/analysis-exercise/data/' # change me!\n",
    "## note - the above filepath should be the only item you will have to change in order to run the notebook\n",
    "## from here on, run everything sequentially and it should work\n",
    "## as long as scikit-learn, pandas, scipy and statsmodels are installed\n",
    "## this is using python 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## INITIAL SETUP\n",
    "\n",
    "## importing packages\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import statsmodels.stats as sts\n",
    "import statsmodels.api\n",
    "import os\n",
    "from __future__ import division\n",
    "\n",
    "## modeling packages (scikit-learn)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "##changing directory and adjusting display settings\n",
    "os.chdir(use_dir)\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "## read in data\n",
    "hires = pd.read_csv('data_exercise_hires.csv')\n",
    "applicants = pd.read_csv('data_exercise_applicants.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client9     1.536424\n",
       "client10    0.452661\n",
       "client4     0.276627\n",
       "client11    0.249813\n",
       "client1          NaN\n",
       "client2          NaN\n",
       "client3          NaN\n",
       "client5          NaN\n",
       "client6          NaN\n",
       "client7          NaN\n",
       "client8          NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Which organizations have the greatest applicant-to-hire ratio?\n",
    "raw_hires = hires.groupby('client').count()['user_id']\n",
    "raw_apps = applicants.groupby('client_name').count()['user_id']\n",
    "app_to_hire = pd.concat([raw_hires, raw_apps], axis = 1)\n",
    "app_to_hire.columns = ['raw_hires','raw_apps']\n",
    "app_to_hire.pct = app_to_hire.raw_hires / app_to_hire.raw_apps\n",
    "app_to_hire.pct.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_name\n",
       "client10    2123\n",
       "client11    6701\n",
       "client4      676\n",
       "client9      453\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check distinct clients in applicant data\n",
    "applicants.groupby('client_name').count()['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client\n",
       "client1     0.472527\n",
       "client2     0.221698\n",
       "client4     0.194969\n",
       "client5     0.143089\n",
       "client7     0.132275\n",
       "client6     0.116279\n",
       "client11    0.100709\n",
       "client3     0.060787\n",
       "client10    0.059113\n",
       "client9     0.050167\n",
       "client8     0.025532\n",
       "Name: pct, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Which organizations have the greatest challenge with attrition in the first 3 months of employment?\n",
    "\n",
    "## looking at tenure <= 90 days for employees who are no longer employed (assuming this is roughly 3 months)\n",
    "first_three_mos = hires[(hires.tenure_length <= 90) & (hires.currently_employed == 'N')].groupby('client').count()['tenure_length']\n",
    "total_hires = hires[hires.currently_employed == 'N'].groupby('client').count()['tenure_length']\n",
    "\n",
    "# get the percent of no-longer-employed individuals who turned over in three months\n",
    "first3mos = pd.concat([first_three_mos, total_hires], axis=1)\n",
    "first3mos.columns = ['tenure_less_3mos', 'all_tenure']\n",
    "first3mos['pct'] = first3mos.tenure_less_3mos / first3mos.all_tenure\n",
    "\n",
    "first3mos['pct'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nursing\n",
      "\ttotal hires: 3102\n",
      "\tpct 6 mo attrition: 0.057\n",
      "administrative\n",
      "\ttotal hires: 300\n",
      "\tpct 6 mo attrition: 0.047\n",
      "patient_care\n",
      "\ttotal hires: 1694\n",
      "\tpct 6 mo attrition: 0.069\n",
      "housekeeping\n",
      "\ttotal hires: 317\n",
      "\tpct 6 mo attrition: 0.107\n",
      "aide\n",
      "\ttotal hires: 292\n",
      "\tpct 6 mo attrition: 0.116\n",
      "dietary\n",
      "\ttotal hires: 432\n",
      "\tpct 6 mo attrition: 0.12\n",
      "sales\n",
      "\ttotal hires: 75\n",
      "\tpct 6 mo attrition: 0.067\n",
      "director\n",
      "\ttotal hires: 28\n",
      "\tpct 6 mo attrition: 0.0\n",
      "other\n",
      "\ttotal hires: 130\n",
      "\tpct 6 mo attrition: 0.077\n",
      "nursing_assistant\n",
      "\ttotal hires: 610\n",
      "\tpct 6 mo attrition: 0.107\n",
      "lab\n",
      "\ttotal hires: 136\n",
      "\tpct 6 mo attrition: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Do 6 month attrition rates vary significantly across different job categories?\n",
    "for job in hires.hire_job_category.unique():\n",
    "    less_60 = hires[(hires.tenure_length <= 60) & (hires.hire_job_category == job)].count()['user_id']\n",
    "    total = hires[hires.hire_job_category==job].count()['user_id']\n",
    "    pct = less_60 / total\n",
    "    print job+'\\n\\ttotal hires: '+str(total)+'\\n\\tpct 6 mo attrition: '+str(round(pct,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nursing (-4.2781491306386332, 1.8845375269145253e-05)\n",
      "administrative (-1.731750083528518, 0.083318069143836854)\n",
      "patient_care (-0.52604172469593202, 0.59885921691845856)\n",
      "housekeeping (2.4893535875524004, 0.01279756176434018)\n",
      "aide (3.0056818003483796, 0.0026498613648733853)\n",
      "dietary (4.0224870619380075, 5.7586818450984734e-05)\n",
      "sales (-0.17800028154061429, 0.85872275463398706)\n",
      "director (-1.4762912803229575, 0.13986571395700917)\n",
      "other (0.22140721994439619, 0.82477537122322142)\n",
      "nursing_assistant (3.4617021714479463, 0.00053677079666752123)\n",
      "lab (-1.9386334805047032, 0.052545983734292312)\n"
     ]
    }
   ],
   "source": [
    "## z-test for significance, 1 vs rest\n",
    "hires['attrition'] = 0\n",
    "hires.ix[hires.tenure_length<=60, 'attrition'] = 1\n",
    "\n",
    "for job in hires.hire_job_category.unique():\n",
    "    job_attr = hires[hires.hire_job_category == job]['attrition']\n",
    "    other_attr = hires[hires.hire_job_category != job]['attrition']\n",
    "    attr_ztest = sts.weightstats.ztest(job_attr, x2=other_attr, value=0,alternative='two-sided')\n",
    "    print job,attr_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7116"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for next part, combine data sets\n",
    "combined_data = applicants.join(hires, on='user_id', how='outer', rsuffix = '_hires')\n",
    "\n",
    "## check quality of join\n",
    "len(combined_data[(combined_data.user_id_hires.notnull()) & (combined_data.user_id.notnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "iPhone Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-N900T Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "ZTE Z987 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SPH-L720 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Other Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G900T Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "LG-D415 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "iPad Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "HTC Desire 510 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G900V Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SCH-I415 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "XT1254 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-T320 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-N910P Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "N9520 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SPH-L710 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Alcatel One Touch Fierce Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "HTC 6525LVW Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "LGMS769 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SGH-I717 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-P900 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SGH-I527 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-N900A Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Z987 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Z970 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Trio AXS 4G Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "LGLS660 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "0PCV1 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G530AZ Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G870A Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-S765C Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "LGL34C Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G920A Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "LG-D631 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SPH-L520 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SGH-I537 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "HTC 0PCV220 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-G900A Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SGH-I337 Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-N910A Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-S820L Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "HTC Desire 626s Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SM-N910T Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Samsung SGH-M919 Ttest_indResult(statistic=nan, pvalue=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\numpy\\core\\_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "## How does the type of device used to take the questionnaire impact an applicantâ€™s tenure length, if at all?\n",
    "for d in combined_data.device.unique():\n",
    "    unique_device = combined_data[combined_data.device == d]['tenure_length']\n",
    "    other_devices = combined_data[(combined_data.device.notnull())&(combined_data.device != d)]['tenure_length']\n",
    "    device_ttest = ss.ttest_ind(unique_device, other_devices)\n",
    "    print d,device_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check to see if we actually have any data to work with\n",
    "len(combined_data[(combined_data['device'].notnull())&(combined_data['tenure_length'].notnull())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PRE-PROCESSING ##\n",
    "\n",
    "## create flags for categorical variables: job category, client, current employ\n",
    "for job in combined_data[combined_data.hire_job_category.notnull()].hire_job_category.unique():\n",
    "    combined_data['category_'+job] = combined_data.hire_job_category.map(lambda x: x == job).astype(int)\n",
    "\n",
    "for client in combined_data[combined_data.client.notnull()].client.unique():\n",
    "    combined_data[client] = combined_data.client.map(lambda x: x == client).astype(int)\n",
    "                         \n",
    "combined_data['current_employ_flag'] = combined_data.currently_employed.map(lambda x: x == 'Y').astype(int)\n",
    "                         \n",
    "## create outcome(y) variable\n",
    "combined_data['tenure'] = 'none'\n",
    "combined_data.ix[combined_data.tenure_length<182, 'tenure'] = 'less6'\n",
    "combined_data.ix[(combined_data.tenure_length>=182)&(combined_data.tenure_length<365), 'tenure'] = '6_12'                         \n",
    "combined_data.ix[combined_data.tenure_length>=365, 'tenure'] = '12plus'\n",
    "                         \n",
    "## variables to not include as model inputs\n",
    "drop_columns = ['device','tenure_length','client_name','client','user_id','user_id_hires','currently_employed']                         \n",
    "\n",
    "#separate out into train/test and X,y \n",
    "#drop undesired variables, exclude non-numeric features for redundancy in case any were missed above\n",
    "data = dict()\n",
    "data['X'] = combined_data[combined_data.tenure != 'none'].drop(drop_columns, axis=1).fillna(0).select_dtypes(exclude=[object]).copy()\n",
    "data['y'] = combined_data[combined_data.tenure != 'none']['tenure'].copy()\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data['X'], data['y'], test_size=0.30, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest Index([u'attrition', u'category_nursing', u'client3', u'client8', u'client1',\n",
      "       u'client2', u'current_employ_flag'],\n",
      "      dtype='object')\n",
      "number of features: 7\n",
      "logistic regression Index([u'answer1', u'answer2', u'answer3', u'answer4', u'answer5', u'answer6',\n",
      "       u'answer7', u'answer8', u'answer9', u'answer10', u'answer11',\n",
      "       u'answer12', u'answer13', u'answer14', u'answer15', u'answer16',\n",
      "       u'answer17', u'answer18', u'answer19', u'answer20', u'answer21',\n",
      "       u'answer22', u'answer23', u'answer24', u'answer25', u'log_total_time',\n",
      "       u'attrition', u'category_other', u'category_nursing',\n",
      "       u'category_dietary', u'category_patient_care',\n",
      "       u'category_nursing_assistant', u'category_aide',\n",
      "       u'category_housekeeping', u'category_lab', u'category_administrative',\n",
      "       u'category_sales', u'category_director', u'client3', u'client4',\n",
      "       u'client5', u'client7', u'client8', u'client9', u'client10',\n",
      "       u'client11', u'client1', u'client2', u'client6',\n",
      "       u'current_employ_flag'],\n",
      "      dtype='object')\n",
      "number of features: 50\n"
     ]
    }
   ],
   "source": [
    "## FEATURE SELECTION ##\n",
    "\n",
    "# setting up models + hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=21)\n",
    "lm = LogisticRegression(fit_intercept=True, random_state=21)\n",
    "\n",
    "# feature selection\n",
    "model_types = [rf, lm]\n",
    "names = ['random forest', 'logistic regression']\n",
    "x_train = dict()\n",
    "x_test = dict()\n",
    "for mtype, name in zip(model_types,names):\n",
    "    select = SelectFromModel(estimator=mtype,threshold=0.02, prefit=False)\n",
    "    select.fit_transform(Xtrain,ytrain)\n",
    "    features = select.get_support()\n",
    "    x_train[mtype] = Xtrain[Xtrain.columns[features]]\n",
    "    x_test[mtype] = Xtest[Xtest.columns[features]]\n",
    "    print name, Xtrain.columns[features]\n",
    "    print 'number of features: {}'.format(len(Xtrain.columns[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MODELING ## \n",
    "\n",
    "# fit the models\n",
    "models = dict()\n",
    "for mtype in model_types:\n",
    "    X_train = x_train[mtype]\n",
    "    models[mtype] = mtype.fit(X_train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get predictions based on the models\n",
    "preds = dict()\n",
    "for mtype in model_types:\n",
    "    X_test = x_test[mtype]\n",
    "    preds[mtype] = models[mtype].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get labels for outcomes\n",
    "labels = ytest.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random forest:\n",
      "12plus [ 0.70845481  0.47337278  0.83544304]\n",
      "6_12 [ 0.9559402   0.17857143  0.49253731]\n",
      "less6 [ 0.81379772  0.25931929  0.61971831]\n",
      "        12plus  6_12  less6\n",
      "12plus    1215    39     17\n",
      "6_12       346    80     22\n",
      "less6      154    50    198\n",
      "\n",
      "logistic regression:\n",
      "12plus [ 0.71085044  0.46491228  0.7384106 ]\n",
      "6_12 [ 0.95357986  0.11830357  0.55472637]\n",
      "less6 [ 0.81451613  0.1886121   0.63352273]\n",
      "        12plus  6_12  less6\n",
      "12plus    1212    33     26\n",
      "6_12       342    53     53\n",
      "less6      151    28    223\n"
     ]
    }
   ],
   "source": [
    "## MODEL EVALUATION ##\n",
    "\n",
    "# precision, recall, F-beta scores and print a confusion matrix\n",
    "for mtype, name in zip(model_types, names):\n",
    "    scores = metrics.precision_recall_fscore_support(ytest, preds[mtype])\n",
    "    print '\\n'+name+':'\n",
    "    print labels[0],scores[0]\n",
    "    print labels[1],scores[1]\n",
    "    print labels[2],scores[2]\n",
    "    print pd.DataFrame(metrics.confusion_matrix(ytest, preds[mtype]),index=labels,columns=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
